{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try-it 8.1: The \"Best\" Model\n",
    "\n",
    "This module was all about regression and using Python's scikitlearn library to build regression models.  Below, a dataset related to real estate prices in California is given. While many of the assignments you have built and evaluated different models, it is important to spend some time interpreting the resulting \"best\" model.  \n",
    "\n",
    "\n",
    "Your goal is to build a regression model to predict the price of a house in California.  After doing so, you are to *interpret* the model.  There are many strategies for doing so, including some built in methods from scikitlearn.  One example is `permutation_importance`.  Permutation feature importance is a strategy for inspecting a model and its features importance.  \n",
    "\n",
    "Take a look at the user guide for `permutation_importance` [here](https://scikit-learn.org/stable/modules/permutation_importance.html).  Use  the `sklearn.inspection` modules implementation of `permutation_importance` to investigate the importance of different features to your regression models.  Share these results on the discussion board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali = pd.read_csv('data/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "cali.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- It looks like feature total_bedrooms has missing value, roughly around 207 data points.\n",
    "- Since we are observing the median value of both income and house value, for the sake of consistency, let's perform a median imputation.\n",
    "- Sklearn has a module called SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "cali['total_bedrooms'] = imputer.fit_transform(cali[['total_bedrooms']])\n",
    "\n",
    "# let's check the missing value\n",
    "cali['total_bedrooms'].isnull().sum()\n",
    "\n",
    "cali.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have no more missing values.\n",
    "\n",
    "Let's decide what are we predicting using what features do we need for the model. Also, we need to decide how much data we are going to use for training. Then once we get models ready for prediction on testing data, we need to compare which model best predicting the unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting X and y dataset\n",
    "X = cali.drop('median_house_value', axis=1)\n",
    "y = cali['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline for testing data: 13104089782.408998\n"
     ]
    }
   ],
   "source": [
    "# we want to observe how much error between the mean and the ground truth testing data\n",
    "baseline_train = np.ones(shape=y_train.shape)*y_train.mean()\n",
    "baseline_test = np.ones(shape=y_test.shape)*y_test.mean()\n",
    "\n",
    "mse_baseline_train = mean_squared_error(y_train, baseline_train)\n",
    "mse_baseline_test = mean_squared_error(y_test, baseline_test)\n",
    "\n",
    "print(f'Baseline for testing data: {mse_baseline_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different in two function np.ones() and np.full_like() yield slight different number due to floating-point arithmetic precision or rounding differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the categories feature is ocean_proximity\n",
    "# let create one hot coding feature model\n",
    "\n",
    "ocean_proximity_train = X_train[['ocean_proximity']]\n",
    "ocean_proximity_test = X_test[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='if_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ohe_train = ohe.fit_transform(ocean_proximity_train)\n",
    "model_ohe_test = ohe.transform(ocean_proximity_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ohe = LinearRegression().fit(model_ohe_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Coding for testing data: 9877034768.580427\n"
     ]
    }
   ],
   "source": [
    "model_ohe_preds = model_ohe.predict(model_ohe_test)\n",
    "mse_test = mean_squared_error(model_ohe_preds, y_test)\n",
    "\n",
    "print(f'One Hot Coding for testing data: {mse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4908476721.156556, 4496494023.057793, 10423035059.009874, 29334469524930.312, 6443795526368757.0]\n"
     ]
    }
   ],
   "source": [
    "# lastly, we want to model both with features one hot coding from categorical variable\n",
    "# and polynomial features of numerical features\n",
    "\n",
    "test_mses = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    poly_ordinal_ohe = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),\n",
    "                                               (OneHotEncoder(drop = 'if_binary'), ['ocean_proximity']))\n",
    "    pipe = Pipeline([('transformer', poly_ordinal_ohe), ('linreg', LinearRegression())])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    p2 = pipe.predict(X_test)\n",
    "\n",
    "    test_mses.append(mean_squared_error(y_test, p2))\n",
    "\n",
    "print(test_mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these result yield the same number as the module. That is a good sign that my code work well and cleaner.\n",
    "\n",
    "As we observe, the model Degree 2 + One Hot Coding: MSE = 4,496,494,023.057793 (Best Performance)\n",
    "\n",
    "Please check my class module that perform the step above in one function: ModelComparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting + Model Fitting + Model Comparison Integration\n",
    "\n",
    "Since we have to create so many function and messy, I decided to create a class that would perform all these task simultaneuous for cleaner code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelComparison import ModelComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Baseline Model': 13106960720.039366, 'One-Hot Model': 9876284291.152872, 'Poly + One-Hot Model': 10423035059.009874}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define target column and feature columns\n",
    "target_column = 'median_house_value'\n",
    "categorical_columns = ['ocean_proximity']\n",
    "numerical_columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "                     'total_bedrooms', 'population', 'households', 'median_income']\n",
    "\n",
    "# Instantiate the ModelComparison class\n",
    "model_comparison = ModelComparison(dataframe=cali, \n",
    "                                   target_column=target_column, \n",
    "                                   categorical_columns=categorical_columns, \n",
    "                                   numerical_columns=numerical_columns,\n",
    "                                   poly_degree=3)\n",
    "\n",
    "# Fit the models and calculate MSE\n",
    "model_comparison.fit()\n",
    "\n",
    "# Retrieve and print the MSE for each model\n",
    "model_performance = model_comparison.get_model_performance()\n",
    "print(model_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class, I split the data 20% test size and random value=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1: MSE = 4908476721.156556\n",
      "Degree 2: MSE = 4496494023.057793\n",
      "Degree 3: MSE = 10423035059.009874\n",
      "Degree 4: MSE = 29334469524930.312\n",
      "Degree 5: MSE = 6443795526368757.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define target and feature columns\n",
    "target_column = 'median_house_value'\n",
    "categorical_columns = ['ocean_proximity']\n",
    "numerical_columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "                     'total_bedrooms', 'population', 'households', 'median_income']\n",
    "\n",
    "# Range of polynomial degrees you want to test\n",
    "poly_degrees = range(1, 6)  # For example, degrees 1 through 4\n",
    "\n",
    "# Dictionary to store MSEs for each degree\n",
    "degree_mse = {}\n",
    "\n",
    "# Loop over each degree, instantiate the class, fit models, and store performance\n",
    "for degree in poly_degrees:\n",
    "    model_comparison = ModelComparison(dataframe=cali, \n",
    "                                       target_column=target_column, \n",
    "                                       categorical_columns=categorical_columns, \n",
    "                                       numerical_columns=numerical_columns,\n",
    "                                       poly_degree=degree)\n",
    "    model_comparison.fit()\n",
    "    model_performance = model_comparison.get_model_performance()\n",
    "    \n",
    "    # the MSE of the Poly + One-Hot Model\n",
    "    mse_for_degree = model_performance.get('Poly + One-Hot Model')\n",
    "    degree_mse[degree] = mse_for_degree\n",
    "\n",
    "# Print MSEs for each degree\n",
    "for degree, mse in degree_mse.items():\n",
    "    print(f\"Degree {degree}: MSE = {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree: 2 with MSE: 4496494023.057793\n"
     ]
    }
   ],
   "source": [
    "best_degree = min(degree_mse, key=degree_mse.get)  # Finds the degree with the lowest MSE\n",
    "best_mse = degree_mse[best_degree]\n",
    "print(f\"Best degree: {best_degree} with MSE: {best_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_comparison = ModelComparison(dataframe=cali, \n",
    "                                        target_column=target_column, \n",
    "                                        categorical_columns=categorical_columns, \n",
    "                                        numerical_columns=numerical_columns,\n",
    "                                        poly_degree=best_degree)\n",
    "best_model_comparison.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Poly + One-Hot Model with MSE: 4496494023.057793\n"
     ]
    }
   ],
   "source": [
    "best_model_name, best_mse, best_model = best_model_comparison.get_best_model()\n",
    "print(f\"Best model: {best_model_name} with MSE: {best_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79111.3992028 ,  87206.94064916, 272325.57262656, ...,\n",
       "       464827.11268383, 106487.99352048, 187313.3832815 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (Mean Decrease in Performance):\n",
      "latitude: 1.920732685581489\n",
      "longitude: 1.842702395403527\n",
      "total_rooms: 1.6949432056070677\n",
      "total_bedrooms: 1.3165710442403553\n",
      "households: 0.9845214833281576\n",
      "median_income: 0.8980990528934527\n",
      "population: 0.6366297349437874\n",
      "housing_median_age: 0.07165923245163114\n",
      "ocean_proximity: 0.023049872401397442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Organizing and displaying feature importances\n",
    "importances = result.importances_mean\n",
    "features = X_test.columns\n",
    "feature_importance_dict = {feature: importance for feature, importance in zip(features, importances)}\n",
    "sorted_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance (Mean Decrease in Performance):\")\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
